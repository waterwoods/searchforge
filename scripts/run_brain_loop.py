#!/usr/bin/env python3
"""
AutoTuner Brain è¿­ä»£éªŒè¯è„šæœ¬

æµ‹è¯•è°ƒä¼˜å™¨æ˜¯å¦ä¼šæ”¶æ•›ï¼Œä¸ä¼šæ— é™éœ‡è¡ã€‚
ä» fixtures é€‰æ‹©å…³é”®æ ·ä¾‹ï¼Œè¿ç»­è°ƒç”¨å†³ç­–å’Œåº”ç”¨å‡½æ•°å¤šè½®ï¼Œ
è§‚å¯Ÿå‚æ•°å˜åŒ–è¶‹åŠ¿å’Œæ€§èƒ½æŒ‡æ ‡çš„æ”¶æ•›æƒ…å†µã€‚
"""

import sys
import os

# æ·»åŠ æ¨¡å—è·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

from modules.autotuner.brain.fixtures import get_fixture_by_name
from modules.autotuner.brain.decider import decide_tuning_action
from modules.autotuner.brain.apply import apply_action
from modules.autotuner.brain.contracts import SLO, Guards
from typing import List, Dict, Any


def format_params(params: Dict[str, Any]) -> str:
    """æ ¼å¼åŒ–å‚æ•°å­—å…¸ä¸ºç®€æ´å­—ç¬¦ä¸²"""
    return f"ef={params['ef']}, T={params['T']}, Ncand_max={params['Ncand_max']}, rerank_mult={params['rerank_mult']}"


def simulate_performance_change(params: Dict[str, Any], action_kind: str) -> tuple:
    """
    æ¨¡æ‹Ÿå‚æ•°å˜åŒ–å¯¹æ€§èƒ½çš„å½±å“ï¼ˆåŸºäºçœŸå®åœºæ™¯çš„æ¨¡å‹ï¼‰
    
    Args:
        params: å½“å‰å‚æ•°
        action_kind: åŠ¨ä½œç±»å‹
        
    Returns:
        (p95_ms, recall_at10) æ¨¡æ‹Ÿçš„æ€§èƒ½æŒ‡æ ‡
    """
    # åŸºç¡€æ€§èƒ½ï¼ˆåŸºäºå®é™…è§‚å¯Ÿï¼‰
    base_p95 = 120.0
    base_recall = 0.75
    
    # ef å¯¹æ€§èƒ½çš„å½±å“ï¼ˆä¸»è¦å½±å“å¬å›å’Œå»¶è¿Ÿï¼‰
    ef_factor = (params['ef'] - 64) / (256 - 64)  # 0-1 å½’ä¸€åŒ–
    p95_impact = ef_factor * 120  # ef ä» 64->256ï¼Œå»¶è¿Ÿå¢åŠ  120ms
    recall_impact = ef_factor * 0.20  # ef ä» 64->256ï¼Œå¬å›æå‡ 0.20
    
    # T å¯¹æ€§èƒ½çš„å½±å“ï¼ˆä¸´ç•ŒåŒºæ•ˆåº”ï¼‰
    if params['T'] > 400:  # è¶…è¿‡ä¸´ç•Œç‚¹ï¼Œèµ°å†…å­˜è·¯å¾„
        p95_impact -= 30  # å»¶è¿Ÿé™ä½
        recall_impact += 0.03  # å¬å›ç•¥æœ‰æå‡
    
    # Ncand_max å¯¹æ€§èƒ½çš„å½±å“
    ncand_factor = (params['Ncand_max'] - 500) / (2000 - 500)  # 0-1 å½’ä¸€åŒ–
    p95_impact += ncand_factor * 100  # ncand ä» 500->2000ï¼Œå»¶è¿Ÿå¢åŠ  100ms
    recall_impact += ncand_factor * 0.12  # ncand ä» 500->2000ï¼Œå¬å›æå‡ 0.12
    
    # rerank_mult å¯¹æ€§èƒ½çš„å½±å“
    rerank_factor = (params['rerank_mult'] - 2) / (6 - 2)  # 0-1 å½’ä¸€åŒ–
    p95_impact += rerank_factor * 80  # rerank ä» 2->6ï¼Œå»¶è¿Ÿå¢åŠ  80ms
    recall_impact += rerank_factor * 0.10  # rerank ä» 2->6ï¼Œå¬å›æå‡ 0.10
    
    # è®¡ç®—æœ€ç»ˆæ€§èƒ½
    final_p95 = base_p95 + p95_impact
    final_recall = base_recall + recall_impact
    
    # ç¡®ä¿åœ¨åˆç†èŒƒå›´å†…
    final_p95 = max(60.0, min(600.0, final_p95))
    final_recall = max(0.65, min(0.95, final_recall))
    
    return final_p95, final_recall


def run_iteration_test(fixture_name: str, max_iterations: int = 5) -> List[Dict]:
    """
    å¯¹å•ä¸ªæµ‹è¯•ç”¨ä¾‹è¿è¡Œè¿­ä»£è°ƒä¼˜æµ‹è¯•
    
    Args:
        fixture_name: æµ‹è¯•ç”¨ä¾‹åç§°
        max_iterations: æœ€å¤§è¿­ä»£æ¬¡æ•°
        
    Returns:
        è¿­ä»£å†å²è®°å½•
    """
    print(f"\n{'='*60}")
    print(f"è¿­ä»£æµ‹è¯•: {fixture_name}")
    print(f"{'='*60}")
    
    # è·å–åˆå§‹è¾“å…¥
    initial_inp = get_fixture_by_name(fixture_name)
    
    # åˆå§‹åŒ–çŠ¶æ€ - ä½¿ç”¨æ›´çœŸå®çš„åˆå§‹æ€§èƒ½æŒ‡æ ‡
    current_params = initial_inp.params.copy()
    
    # æ ¹æ®æµ‹è¯•ç”¨ä¾‹ç±»å‹è®¾ç½®åˆå§‹æ€§èƒ½
    if "high_latency" in fixture_name:
        current_p95, current_recall = 250.0, 0.92  # é«˜å»¶è¿Ÿ+å¬å›å¯Œä½™
    elif "low_recall" in fixture_name:
        current_p95, current_recall = 90.0, 0.80   # ä½å¬å›+å»¶è¿Ÿå¯Œä½™
    elif "ef_at_min" in fixture_name:
        current_p95, current_recall = 240.0, 0.90  # efå·²è¾¾æœ€å°å€¼+é«˜å»¶è¿Ÿ
    elif "ef_at_max" in fixture_name:
        current_p95, current_recall = 90.0, 0.82   # efå·²è¾¾æœ€å¤§å€¼+ä½å¬å›
    else:
        current_p95, current_recall = simulate_performance_change(current_params, "initial")
    
    # SLO å’Œå®ˆæŠ¤æ¡ä»¶ï¼ˆä¿æŒä¸å˜ï¼‰
    slo = initial_inp.slo
    guards = Guards(cooldown=False, stable=True)  # å‡è®¾ç¨³å®šçŠ¶æ€
    near_T = initial_inp.near_T
    
    history = []
    
    for iteration in range(max_iterations):
        print(f"\n--- ç¬¬ {iteration + 1} è½® ---")
        print(f"å½“å‰æ€§èƒ½: p95={current_p95:.1f}ms, recall={current_recall:.3f}")
        print(f"å½“å‰å‚æ•°: {format_params(current_params)}")
        
        # åˆ›å»ºè°ƒä¼˜è¾“å…¥
        tuning_input = type(initial_inp)(
            p95_ms=current_p95,
            recall_at10=current_recall,
            qps=100.0,
            params=current_params,
            slo=slo,
            guards=guards,
            near_T=near_T,
            last_action=history[-1]['action'] if history else None,
            adjustment_count=len(history) if history else 0
        )
        
        # å†³ç­–
        action = decide_tuning_action(tuning_input)
        print(f"å†³ç­–: {action.kind} (step={action.step}, reason='{action.reason}')")
        
        # åº”ç”¨åŠ¨ä½œ
        new_params = apply_action(current_params, action)
        
        # è®°å½•å†å²
        history.append({
            'iteration': iteration + 1,
            'p95_ms': current_p95,
            'recall_at10': current_recall,
            'params': current_params.copy(),
            'action': action,
            'new_params': new_params.copy(),
            'slo': slo
        })
        
        # æ£€æŸ¥æ˜¯å¦æ”¶æ•›ï¼ˆè¿ç»­ä¸¤è½®éƒ½æ˜¯ noopï¼‰
        if action.kind == "noop":
            print("âœ… æ”¶æ•›ï¼šå†³ç­–ä¸º noop")
            break
        
        # æ›´æ–°å‚æ•°
        current_params = new_params
        
        # æ¨¡æ‹Ÿæ€§èƒ½å˜åŒ–
        current_p95, current_recall = simulate_performance_change(current_params, action.kind)
        
        # æ£€æŸ¥å‚æ•°æ˜¯å¦è¿˜åœ¨å˜åŒ–
        if iteration > 0:
            prev_params = history[-2]['params']
            params_changed = any(current_params[key] != prev_params[key] 
                               for key in current_params.keys())
            if not params_changed:
                print("âœ… æ”¶æ•›ï¼šå‚æ•°ä¸å†å˜åŒ–")
                break
    
    print(f"\n--- è¿­ä»£å®Œæˆï¼Œå…± {len(history)} è½® ---")
    return history


def analyze_convergence(history: List[Dict]) -> bool:
    """
    åˆ†ææ˜¯å¦æ”¶æ•›
    
    Args:
        history: è¿­ä»£å†å²
        
    Returns:
        æ˜¯å¦æ”¶æ•›
    """
    if len(history) < 2:
        return True
    
    # æ£€æŸ¥æœ€åå‡ è½®æ˜¯å¦ç¨³å®šï¼ˆè¿ç»­noopï¼‰
    last_actions = [h['action'].kind for h in history[-2:]]
    if all(action == "noop" for action in last_actions):
        return True
    
    # æ£€æŸ¥å‚æ•°æ˜¯å¦ç¨³å®šï¼ˆè¿ç»­ç›¸åŒå‚æ•°ï¼‰
    if len(history) >= 2:
        last_params = [h['params'] for h in history[-2:]]
        params_stable = all(
            last_params[i] == last_params[i-1] 
            for i in range(1, len(last_params))
        )
        if params_stable:
            return True
    
    # æ£€æŸ¥æ˜¯å¦åœ¨SLOèŒƒå›´å†…ä¸”ç¨³å®š
    if len(history) >= 1:
        last_h = history[-1]
        slo = last_h.get('slo')
        if slo:
            p95_ok = last_h['p95_ms'] <= slo.p95_ms
            recall_ok = last_h['recall_at10'] >= slo.recall_at10
            if p95_ok and recall_ok and last_h['action'].kind == "noop":
                return True
    
    return False


def print_convergence_summary(fixture_name: str, history: List[Dict]):
    """æ‰“å°æ”¶æ•›æ€§åˆ†ææ‘˜è¦"""
    print(f"\nğŸ“Š æ”¶æ•›æ€§åˆ†æ - {fixture_name}")
    print("-" * 40)
    
    if not history:
        print("âŒ æ— è¿­ä»£å†å²")
        return
    
    converged = analyze_convergence(history)
    print(f"æ”¶æ•›çŠ¶æ€: {'âœ… æ”¶æ•›' if converged else 'âš ï¸ æœªå®Œå…¨æ”¶æ•›'}")
    print(f"è¿­ä»£è½®æ•°: {len(history)}")
    
    if len(history) > 1:
        # å‚æ•°å˜åŒ–è½¨è¿¹
        print("\nå‚æ•°å˜åŒ–è½¨è¿¹:")
        for i, h in enumerate(history):
            params_str = format_params(h['params'])
            action_str = f"{h['action'].kind}({h['action'].step})"
            print(f"  ç¬¬{i+1}è½®: {params_str} -> {action_str}")
        
        # æ€§èƒ½å˜åŒ–è½¨è¿¹
        print("\næ€§èƒ½å˜åŒ–è½¨è¿¹:")
        for i, h in enumerate(history):
            print(f"  ç¬¬{i+1}è½®: p95={h['p95_ms']:.1f}ms, recall={h['recall_at10']:.3f}")


def main():
    """ä¸»å‡½æ•°"""
    print("AutoTuner Brain è¿­ä»£æ”¶æ•›æ€§æµ‹è¯•")
    print("=" * 60)
    
    # é€‰æ‹©å…³é”®æµ‹è¯•ç”¨ä¾‹
    test_cases = [
        "high_latency_recall_redundant",  # é«˜å»¶è¿Ÿ+å¬å›å¯Œä½™
        "low_recall_latency_margin",      # ä½å¬å›+å»¶è¿Ÿå¯Œä½™
    ]
    
    # å¯ä»¥æ·»åŠ æ›´å¤šæµ‹è¯•ç”¨ä¾‹
    extended_test_cases = [
        "high_latency_recall_redundant",  # é«˜å»¶è¿Ÿ+å¬å›å¯Œä½™
        "low_recall_latency_margin",      # ä½å¬å›+å»¶è¿Ÿå¯Œä½™
        "ef_at_min_drop_ncand",          # efå·²è¾¾æœ€å°å€¼
        "ef_at_max_bump_rerank",         # efå·²è¾¾æœ€å¤§å€¼
    ]
    
    # ä½¿ç”¨æ‰©å±•æµ‹è¯•ç”¨ä¾‹è¿›è¡Œæ›´å…¨é¢çš„éªŒè¯
    test_cases = extended_test_cases
    
    all_results = {}
    
    for test_case in test_cases:
        try:
            history = run_iteration_test(test_case, max_iterations=5)
            all_results[test_case] = history
            print_convergence_summary(test_case, history)
        except Exception as e:
            print(f"âŒ æµ‹è¯•ç”¨ä¾‹ {test_case} å¤±è´¥: {e}")
    
    # æ€»ä½“è¯„ä¼°
    print(f"\n{'='*60}")
    print("æ€»ä½“è¯„ä¼°")
    print(f"{'='*60}")
    
    converged_count = sum(1 for h in all_results.values() if analyze_convergence(h))
    total_count = len(all_results)
    
    print(f"æ”¶æ•›æµ‹è¯•ç”¨ä¾‹: {converged_count}/{total_count}")
    
    if converged_count == total_count:
        print("âœ… å¤§è„‘é€šè¿‡é›†æˆæµ‹è¯•ï¼šæ‰€æœ‰æµ‹è¯•ç”¨ä¾‹éƒ½èƒ½æ”¶æ•›")
    else:
        print("âš ï¸ å¤§è„‘éœ€è¦ä¼˜åŒ–ï¼šéƒ¨åˆ†æµ‹è¯•ç”¨ä¾‹æœªèƒ½æ”¶æ•›")
    
    return converged_count == total_count


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
