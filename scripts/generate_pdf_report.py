#!/usr/bin/env python3
"""
ç”Ÿæˆ AutoTuner ä¸€é¡µ PDF æŠ¥å‘Š
ä½¿ç”¨ matplotlib åˆ›å»ºä¸“ä¸šçš„å•é¡µ PDF
"""

import json
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
from matplotlib.patches import Rectangle, FancyBboxPatch
from matplotlib.backends.backend_pdf import PdfPages
from pathlib import Path
from datetime import datetime
from typing import Dict, Tuple

# ä¸­æ–‡å­—ä½“è®¾ç½®
plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'SimHei', 'STHeiti']
plt.rcParams['axes.unicode_minus'] = False


def get_color(color_name: str) -> Tuple[float, float, float]:
    """è·å–é¢œè‰²RGBå€¼"""
    colors = {
        'green': (0.2, 0.7, 0.3),
        'yellow': (0.9, 0.7, 0.1),
        'red': (0.9, 0.2, 0.2),
        'blue': (0.2, 0.4, 0.8),
        'gray': (0.5, 0.5, 0.5)
    }
    return colors.get(color_name, (0.5, 0.5, 0.5))


def evaluate_scenario(metrics: Dict) -> Dict:
    """è¯„ä¼°å•ä¸ªåœºæ™¯"""
    # è´¨é‡
    q_color = 'green'
    if metrics['p_value'] >= 0.05:
        q_color = 'yellow'
    if metrics['buckets'] < 10:
        q_color = 'yellow'
    if metrics['delta_recall'] < -0.01:
        q_color = 'red'
    
    # SLA
    s_color = 'green'
    if metrics['delta_p95_ms'] > 5:
        s_color = 'yellow'
    if metrics['delta_p95_ms'] > 20:
        s_color = 'red'
    if metrics['safety_rate'] < 0.99:
        s_color = 'yellow'
    if metrics['safety_rate'] < 0.95:
        s_color = 'red'
    
    # æˆæœ¬
    c_color = 'green' if metrics['cost_per_query'] <= 0.00005 else 'yellow'
    if metrics['cost_per_query'] > 0.0001:
        c_color = 'red'
    
    # æ€»åˆ¤å®š
    colors = [q_color, s_color, c_color]
    if all(c == 'green' for c in colors):
        verdict = 'PASS'
    elif 'red' in colors:
        verdict = 'FAIL'
    else:
        verdict = 'WARN'
    
    return {
        'quality_color': q_color,
        'sla_color': s_color,
        'cost_color': c_color,
        'verdict': verdict
    }


def create_pdf_report(data: Dict, output_path: Path):
    """åˆ›å»ºPDFæŠ¥å‘Š"""
    scenarios = data['scenarios']
    timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    
    # åˆ›å»ºPDF
    with PdfPages(output_path) as pdf:
        fig = plt.figure(figsize=(11, 8.5))  # Letter size
        fig.suptitle('AutoTuner ä¸€é¡µæˆæœå¡ï¼š0â€“1 å°æ—¶å¬å›ç‡è¿½è¸ª', 
                     fontsize=18, fontweight='bold', y=0.98)
        
        # æ·»åŠ é¡µçœ‰ä¿¡æ¯
        header_text = f'ç”Ÿæˆæ—¶é—´: {timestamp} | æ•°æ®æ¥æº: ~/Downloads/autotuner_runs/ | å®éªŒæ¨¡å¼: LIVE'
        fig.text(0.5, 0.94, header_text, ha='center', fontsize=9, color='gray')
        
        # åˆ›å»ºå­å›¾å¸ƒå±€
        gs = fig.add_gridspec(5, 3, left=0.08, right=0.92, top=0.88, bottom=0.08,
                              hspace=0.4, wspace=0.3)
        
        # åœºæ™¯æ¦‚è§ˆè¡¨
        ax_table = fig.add_subplot(gs[0, :])
        ax_table.axis('off')
        
        table_data = [['åœºæ™¯', 'é¢„è®¾é…ç½®', 'æ—¶é•¿', 'æ¡¶æ•°', 'Î”Recall', 'Î”P95', 'P-value', 'åˆ¤å®š']]
        
        for scenario_key in sorted(scenarios.keys()):
            metrics = scenarios[scenario_key]
            eval_result = evaluate_scenario(metrics)
            
            verdict_symbol = {'PASS': 'âœ…', 'WARN': 'âš ï¸', 'FAIL': 'âŒ'}[eval_result['verdict']]
            row = [
                f'{scenario_key}',
                f'{metrics["preset"][:20]}...' if len(metrics["preset"]) > 20 else metrics["preset"],
                f'{metrics["duration_sec"]}s',
                f'{metrics["buckets"]}',
                f'+{metrics["delta_recall"]:.3f}',
                f'+{metrics["delta_p95_ms"]:.1f}ms',
                f'{metrics["p_value"]:.3f}',
                f'{verdict_symbol} {eval_result["verdict"]}'
            ]
            table_data.append(row)
        
        table = ax_table.table(cellText=table_data, cellLoc='center', loc='center',
                               colWidths=[0.08, 0.25, 0.08, 0.08, 0.12, 0.12, 0.12, 0.15])
        table.auto_set_font_size(False)
        table.set_fontsize(9)
        table.scale(1, 2)
        
        # è®¾ç½®è¡¨å¤´æ ·å¼
        for i in range(len(table_data[0])):
            cell = table[(0, i)]
            cell.set_facecolor('#4472C4')
            cell.set_text_props(weight='bold', color='white')
        
        # è®¾ç½®æ•°æ®è¡Œæ ·å¼
        for i in range(1, len(table_data)):
            for j in range(len(table_data[i])):
                cell = table[(i, j)]
                cell.set_facecolor('#F2F2F2' if i % 2 == 0 else 'white')
        
        ax_table.text(0.5, 1.2, 'ğŸ“Š åœºæ™¯æ¦‚è§ˆ', transform=ax_table.transAxes,
                     fontsize=12, fontweight='bold', ha='center')
        
        # ä¸ºæ¯ä¸ªåœºæ™¯åˆ›å»ºä¸‰ç»´åº¦å¡ç‰‡
        row_offset = 1
        for idx, scenario_key in enumerate(sorted(scenarios.keys())):
            metrics = scenarios[scenario_key]
            eval_result = evaluate_scenario(metrics)
            
            col = idx
            
            # åœºæ™¯æ ‡é¢˜
            ax_title = fig.add_subplot(gs[row_offset, col])
            ax_title.axis('off')
            ax_title.text(0.5, 0.5, f'åœºæ™¯ {scenario_key}\n{eval_result["verdict"]}', 
                         transform=ax_title.transAxes,
                         fontsize=11, fontweight='bold', ha='center', va='center',
                         bbox=dict(boxstyle='round,pad=0.5', 
                                  facecolor=get_color(eval_result['verdict'].lower() if eval_result['verdict'] != 'WARN' else 'yellow'),
                                  alpha=0.3))
            
            # è´¨é‡å¡
            ax_q = fig.add_subplot(gs[row_offset + 1, col])
            ax_q.axis('off')
            q_color = get_color(eval_result['quality_color'])
            ax_q.add_patch(FancyBboxPatch((0.05, 0.05), 0.9, 0.9, 
                                         boxstyle="round,pad=0.05", 
                                         facecolor=q_color, alpha=0.2,
                                         edgecolor=q_color, linewidth=2))
            
            q_text = f"ğŸ¯ è´¨é‡\n"
            q_text += f"p={metrics['p_value']:.3f}\n"
            q_text += f"æ¡¶æ•°={metrics['buckets']}\n"
            q_text += f"Î”Recall=+{metrics['delta_recall']:.3f}"
            
            ax_q.text(0.5, 0.5, q_text, transform=ax_q.transAxes,
                     fontsize=8, ha='center', va='center')
            
            # SLAå¡
            ax_s = fig.add_subplot(gs[row_offset + 2, col])
            ax_s.axis('off')
            s_color = get_color(eval_result['sla_color'])
            ax_s.add_patch(FancyBboxPatch((0.05, 0.05), 0.9, 0.9,
                                         boxstyle="round,pad=0.05",
                                         facecolor=s_color, alpha=0.2,
                                         edgecolor=s_color, linewidth=2))
            
            s_text = f"âš¡ SLA\n"
            s_text += f"Î”P95=+{metrics['delta_p95_ms']:.1f}ms\n"
            s_text += f"å®‰å…¨={metrics['safety_rate']:.3f}\n"
            s_text += f"åº”ç”¨={metrics['apply_rate']:.3f}"
            
            ax_s.text(0.5, 0.5, s_text, transform=ax_s.transAxes,
                     fontsize=8, ha='center', va='center')
            
            # æˆæœ¬å¡
            ax_c = fig.add_subplot(gs[row_offset + 3, col])
            ax_c.axis('off')
            c_color = get_color(eval_result['cost_color'])
            ax_c.add_patch(FancyBboxPatch((0.05, 0.05), 0.9, 0.9,
                                         boxstyle="round,pad=0.05",
                                         facecolor=c_color, alpha=0.2,
                                         edgecolor=c_color, linewidth=2))
            
            monthly_cost = metrics['cost_per_query'] * 1_000_000
            c_text = f"ğŸ’° æˆæœ¬\n"
            c_text += f"${metrics['cost_per_query']:.6f}/æŸ¥è¯¢\n"
            c_text += f"æœˆä¼°ç®—: ${monthly_cost:.2f}\n"
            c_text += f"(1MæŸ¥è¯¢)"
            
            ax_c.text(0.5, 0.5, c_text, transform=ax_c.transAxes,
                     fontsize=8, ha='center', va='center')
        
        # æ·»åŠ é¡µè„š
        avg_delta_recall = sum(m['delta_recall'] for m in scenarios.values()) / len(scenarios)
        avg_delta_p95 = sum(m['delta_p95_ms'] for m in scenarios.values()) / len(scenarios)
        total_buckets = sum(m['buckets'] for m in scenarios.values())
        
        footer = f'æ€»ç»“: å¹³å‡å¬å›ç‡æå‡ +{avg_delta_recall:.3f} | å¹³å‡P95å˜åŒ– +{avg_delta_p95:.1f}ms | æ€»æ¡¶æ•° {total_buckets}'
        fig.text(0.5, 0.03, footer, ha='center', fontsize=9, style='italic')
        
        fig.text(0.5, 0.01, '*æœ¬æŠ¥å‘Šç”± AutoTuner è‡ªåŠ¨ç”Ÿæˆ*', 
                ha='center', fontsize=8, color='gray')
        
        # ä¿å­˜åˆ°PDF
        pdf.savefig(fig, bbox_inches='tight')
        plt.close()


def main():
    """ä¸»å‡½æ•°"""
    # è¯»å–æ•°æ®
    base_dir = Path(__file__).parent.parent / 'docs'
    metrics_path = base_dir / 'collected_metrics.json'
    
    if not metrics_path.exists():
        print(f"âŒ æœªæ‰¾åˆ°æŒ‡æ ‡æ–‡ä»¶: {metrics_path}")
        return
    
    with open(metrics_path, 'r') as f:
        data = json.load(f)
    
    # ç”ŸæˆPDF
    output_pdf = base_dir / 'one_pager_autotuner.pdf'
    print(f"ğŸ“„ ç”Ÿæˆ PDF æŠ¥å‘Š...")
    create_pdf_report(data, output_pdf)
    print(f"   âœ… {output_pdf}")
    
    return output_pdf


if __name__ == '__main__':
    main()

