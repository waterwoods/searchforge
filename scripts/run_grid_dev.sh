#!/usr/bin/env bash
# run_grid_dev.sh - å¹¶è¡Œæäº¤å°æ‰¹é‡å®éªŒï¼ˆ2-3 å¹¶è¡Œæ§½ï¼‰
# ã€å®ˆé—¨äººã€‘é»˜è®¤èµ°å¿«è·¯ï¼šsample=30, top_kâˆˆ{10,20,30}, fast_mode=true

set -euo pipefail

# å®ˆé—¨äººï¼šæ£€æŸ¥ FULL æˆ– PROD æ¨¡å¼æ ‡è®°
if [ "${FULL:-0}" = "1" ] || [ "${PROD:-0}" = "1" ]; then
    echo ""
    echo "ğŸ”´ è­¦å‘Šï¼šFULL=1 æˆ– PROD=1 å·²è®¾ç½®ï¼Œå°†è¿è¡Œå®Œæ•´/ç”Ÿäº§æ¨¡å¼ï¼"
    echo "   å¦‚éœ€å¿«é€Ÿå¼€å‘ï¼Œè¯·ç§»é™¤è¯¥ç¯å¢ƒå˜é‡ã€‚"
    echo ""
    sleep 2
fi

API_BASE="${API_BASE:-http://localhost:8000}"
PARALLEL="${PARALLEL:-2}"
MAX_POLL="${MAX_POLL:-180}"
POLL_INTERVAL="${POLL_INTERVAL:-5}"

echo "ğŸ”¬ Grid Dev - å¹¶è¡Œå°æ‰¹å®éªŒ"
echo "   API Base: $API_BASE"
echo "   Parallel Slots: $PARALLEL"
echo ""

# å®šä¹‰å®éªŒé…ç½®ï¼ˆtop_k âˆˆ {10,20,30}ï¼‰
declare -a experiments=(
  "10:exp1"
  "20:exp2"
  "30:exp3"
)

# å­˜å‚¨ job IDs
declare -a job_ids=()

# 1. å¹¶è¡Œæäº¤å®éªŒ
echo "ğŸ“¤ Step 1: å¹¶è¡Œæäº¤ ${#experiments[@]} ä¸ªå®éªŒ..."
for exp in "${experiments[@]}"; do
    top_k="${exp%%:*}"
    name="${exp##*:}"
    
    echo "   æäº¤å®éªŒ $name (top_k=$top_k)..."
    
    response=$(curl -fsS -X POST "$API_BASE/api/experiment/run" \
      -H 'content-type: application/json' \
      -d "{
        \"sample\": 30,
        \"top_k\": $top_k,
        \"fast_mode\": true,
        \"rerank\": false,
        \"repeats\": 1,
        \"dataset_name\": \"fiqa_10k_v1\",
        \"qrels_name\": \"fiqa_qrels_10k_v1\"
      }" 2>/dev/null)
    
    job_id=$(echo "$response" | python3 -c "import sys, json; print(json.load(sys.stdin)['job_id'])")
    job_ids+=("$job_id:$top_k:$name")
    echo "     âœ“ $name submitted: $job_id"
    
    # ç®€å•çš„å¹¶è¡Œæ§åˆ¶ï¼šæ¯æäº¤ $PARALLEL ä¸ªï¼Œç­‰å¾…ä¸€ä¸‹
    if [ "${#job_ids[@]}" -ge "$PARALLEL" ]; then
        sleep 2
    fi
done

echo ""
echo "âœ… æ‰€æœ‰å®éªŒå·²æäº¤: ${#job_ids[@]} ä¸ª"
echo ""

# 2. è½®è¯¢æ‰€æœ‰ä½œä¸šç›´åˆ°å®Œæˆ
echo "â³ Step 2: è½®è¯¢æ‰€æœ‰ä½œä¸šç›´åˆ°å®Œæˆ..."
declare -A job_status
for job_entry in "${job_ids[@]}"; do
    job_id="${job_entry%%:*}"
    job_status[$job_id]="RUNNING"
done

for i in $(seq 1 "$MAX_POLL"); do
    sleep "$POLL_INTERVAL"
    
    all_done=true
    for job_entry in "${job_ids[@]}"; do
        job_id="${job_entry%%:*}"
        
        # è·³è¿‡å·²å®Œæˆçš„ä½œä¸š
        if [[ "${job_status[$job_id]}" == "SUCCEEDED" ]] || [[ "${job_status[$job_id]}" == "FAILED" ]]; then
            continue
        fi
        
        status_response=$(curl -fsS "$API_BASE/api/experiment/status/$job_id" 2>/dev/null)
        status=$(echo "$status_response" | python3 -c "import sys, json; print(json.load(sys.stdin).get('job', {}).get('status', 'UNKNOWN'))" 2>/dev/null)
        
        job_status[$job_id]=$status
        
        if [[ "$status" != "SUCCEEDED" ]] && [[ "$status" != "FAILED" ]]; then
            all_done=false
        fi
    done
    
    # æ˜¾ç¤ºå½“å‰çŠ¶æ€
    echo "   [$i/$MAX_POLL] Status:"
    for job_entry in "${job_ids[@]}"; do
        job_id="${job_entry%%:*}"
        remaining="${job_entry#*:}"
        top_k="${remaining%%:*}"
        name="${remaining##*:}"
        echo "     $name (top_k=$top_k): ${job_status[$job_id]}"
    done
    
    if [ "$all_done" = true ]; then
        echo ""
        echo "âœ… æ‰€æœ‰ä½œä¸šå®Œæˆï¼"
        break
    fi
    
    if [ "$i" -eq "$MAX_POLL" ]; then
        echo ""
        echo "âŒ è¶…æ—¶ï¼šéƒ¨åˆ†ä½œä¸šæœªå®Œæˆ"
        exit 1
    fi
done

echo ""

# 3. æ”¶é›†ç»“æœå¹¶ç”Ÿæˆ winners_dev.json
echo "ğŸ“Š Step 3: æ”¶é›†ç»“æœå¹¶ç”Ÿæˆèƒœè€…æŠ¥å‘Š..."
mkdir -p reports

results="[]"
for job_entry in "${job_ids[@]}"; do
    job_id="${job_entry%%:*}"
    remaining="${job_entry#*:}"
    top_k="${remaining%%:*}"
    name="${remaining##*:}"
    
    status="${job_status[$job_id]}"
    
    if [ "$status" = "SUCCEEDED" ]; then
        # è¯»å– metrics.json
        metrics_json=$(docker compose -f /home/andy/searchforge/docker-compose.yml -f /home/andy/searchforge/docker-compose.dev.yml exec -T rag-api cat "/app/.runs/$job_id/metrics.json" 2>/dev/null || echo '{}')
        
        recall=$(echo "$metrics_json" | python3 -c "import sys, json; print(json.load(sys.stdin).get('metrics', {}).get('recall_at_10', 0))" 2>/dev/null)
        p95=$(echo "$metrics_json" | python3 -c "import sys, json; print(json.load(sys.stdin).get('metrics', {}).get('p95_ms', 0))" 2>/dev/null)
        
        echo "   $name: recall@10=$recall, p95_ms=$p95"
        
        # è¿½åŠ åˆ°ç»“æœ
        new_result=$(python3 -c "import json; print(json.dumps({'job_id': '$job_id', 'name': '$name', 'top_k': $top_k, 'recall_at_10': $recall, 'p95_ms': $p95}))")
        results=$(echo "$results" | python3 -c "import sys, json; d=json.load(sys.stdin); d.append($new_result); print(json.dumps(d))")
    else
        echo "   $name: FAILED"
    fi
done

# æ‰¾åˆ°æœ€ä½³é…ç½®ï¼ˆæœ€é«˜ recall@10ï¼‰
winner=$(echo "$results" | python3 -c "
import sys, json
results = json.load(sys.stdin)
if results:
    winner = max(results, key=lambda x: x.get('recall_at_10', 0))
    print(json.dumps(winner, indent=2))
else:
    print(json.dumps({'error': 'no_results'}, indent=2))
")

echo ""
echo "ğŸ† èƒœè€…é…ç½®ï¼š"
echo "$winner"

# ä¿å­˜å®Œæ•´æŠ¥å‘Š
report=$(python3 -c "
import json
report = {
    'experiments': $results,
    'winner': $winner,
    'ts': '$(date -u +%Y-%m-%dT%H:%M:%SZ)'
}
print(json.dumps(report, indent=2))
")

echo "$report" > reports/winners_dev.json
echo ""
echo "âœ… æŠ¥å‘Šå·²ä¿å­˜åˆ° reports/winners_dev.json"

