#!/usr/bin/env python3
"""
mine_diff_cases.py - æŒ–æ˜å¯¹æ¯”æ¨¡å¼çš„å·®å¼‚æ¡ˆä¾‹
"""
import json
import requests
from pathlib import Path
import time
import statistics

# é»˜è®¤æ¨¡æ¿æŸ¥è¯¢
DEFAULT_DEMO_QUERIES = [
    "How to invest in index funds?",
    "What are ETF expense ratios?",
    "Best retirement savings strategies",
    "How does compound interest work?",
    "What is a Roth IRA?",
    "Mortgage refinancing tips",
    "Credit score improvement guide",
    "Tax-loss harvesting explained",
    "Dollar cost averaging benefits",
    "401k contribution limits 2024"
]

API_BASE = "http://localhost:8080"
REPORTS_DIR = Path(__file__).parent.parent / "reports"


def load_or_create_demo_queries(queries_path: Path) -> list[str]:
    """åŠ è½½æˆ–åˆ›å»ºdemoæŸ¥è¯¢åˆ—è¡¨"""
    if queries_path.exists():
        with open(queries_path) as f:
            data = json.load(f)
            return data.get("queries", DEFAULT_DEMO_QUERIES)
    else:
        # åˆ›å»ºé»˜è®¤æŸ¥è¯¢
        queries_path.parent.mkdir(exist_ok=True)
        with open(queries_path, 'w') as f:
            json.dump({"queries": DEFAULT_DEMO_QUERIES}, f, indent=2)
        print(f"âœ“ åˆ›å»ºé»˜è®¤æŸ¥è¯¢æ–‡ä»¶: {queries_path}")
        return DEFAULT_DEMO_QUERIES


def call_search_api(query: str, mode: str) -> dict:
    """è°ƒç”¨æœç´¢API"""
    try:
        response = requests.get(
            f"{API_BASE}/search",
            params={"query": query, "mode": mode, "top_k": 10},
            timeout=10
        )
        response.raise_for_status()
        return response.json()
    except Exception as e:
        print(f"âš ï¸  APIè°ƒç”¨å¤±è´¥ (mode={mode}): {e}")
        return None


def compute_doc_id_diff(off_ids: list[str], on_ids: list[str]) -> int:
    """è®¡ç®—doc_idé›†åˆå·®å¼‚æ•°é‡"""
    off_set = set(off_ids)
    on_set = set(on_ids)
    return len(off_set.symmetric_difference(on_set))


def compute_rank_delta(off_ids: list[str], on_ids: list[str]) -> int:
    """è®¡ç®—OFF Top-1 åœ¨ ON ä¸­çš„æ’åå˜åŒ–"""
    if not off_ids or not on_ids:
        return 0
    
    off_top1 = off_ids[0]
    try:
        on_rank = on_ids.index(off_top1) + 1  # 1-based
        return on_rank - 1  # æ­£æ•°è¡¨ç¤ºæå‡ï¼ˆåœ¨ONä¸­æ’åæ›´é å‰ï¼‰
    except ValueError:
        # OFF Top-1 ä¸åœ¨ ON ç»“æœä¸­
        return -99


def extract_trigger_reason(query: str, off_result: dict, on_result: dict) -> str:
    """æå–è§¦å‘åŸå› """
    reasons = []
    
    # é•¿åº¦è§¦å‘
    if len(query) >= 15:
        reasons.append("len")
    
    # å…³é”®è¯è§¦å‘ (ç®€åŒ–åˆ¤æ–­)
    keywords = ["etf", "yield", "roi", "401k", "bond", "tax", "credit", "mortgage", "invest", "fund"]
    if any(kw in query.lower() for kw in keywords):
        reasons.append("kw")
    
    # åˆ†æ•£åº¦è§¦å‘ (åŸºäºç»“æœå·®å¼‚æ¨æ–­)
    if compute_doc_id_diff(off_result.get("doc_ids", []), on_result.get("doc_ids", [])) >= 5:
        reasons.append("dispersion")
    
    return "|".join(reasons) if reasons else "none"


def mine_diff_cases():
    """æŒ–æ˜å·®å¼‚æ¡ˆä¾‹"""
    print("=" * 60)
    print("ğŸ” å¯¹æ¯”æŒ–æ˜å¼€å§‹...")
    print("=" * 60)
    
    # åŠ è½½æŸ¥è¯¢
    queries_path = REPORTS_DIR / "demo_queries.json"
    queries = load_or_create_demo_queries(queries_path)
    print(f"âœ“ åŠ è½½ {len(queries)} æ¡æŸ¥è¯¢")
    
    # å¯¹æ¯”ç»“æœ
    compare_items = []
    
    for i, query in enumerate(queries, 1):
        print(f"\n[{i}/{len(queries)}] {query}")
        
        # è°ƒç”¨ OFF å’Œ ON
        off_result = call_search_api(query, "off")
        time.sleep(0.5)  # é¿å…è§¦å‘é™æµï¼ˆæ¯ç§’æœ€å¤š3ä¸ªè¯·æ±‚ï¼‰
        on_result = call_search_api(query, "on")
        time.sleep(0.5)
        
        if not off_result or not on_result:
            print("  âš ï¸  è·³è¿‡ï¼ˆAPIè°ƒç”¨å¤±è´¥ï¼‰")
            continue
        
        # æå– doc_ids
        off_ids = off_result.get("doc_ids", [])
        on_ids = on_result.get("doc_ids", [])
        
        # è®¡ç®—å·®å¼‚
        doc_diff = compute_doc_id_diff(off_ids, on_ids)
        rank_delta = compute_rank_delta(off_ids, on_ids)
        trigger_reason = extract_trigger_reason(query, off_result, on_result)
        
        # æå– evidence_span (å‰50å­—)
        evidence_span = ""
        if on_result.get("answers"):
            evidence_span = on_result["answers"][0][:50]
        
        print(f"  doc_diff={doc_diff}, rank_delta={rank_delta}, trigger={trigger_reason}")
        
        compare_items.append({
            "query": query,
            "doc_id_diff": doc_diff,
            "best_rank_delta": rank_delta,
            "trigger_reason": trigger_reason,
            "evidence_span": evidence_span,
            "off": {
                "doc_ids": off_ids,
                "top3": off_result.get("answers", [])[:3]
            },
            "on": {
                "doc_ids": on_ids,
                "top3": on_result.get("answers", [])[:3]
            }
        })
    
    # ç­›é€‰å‰20æ¡æ»¡è¶³æ¡ä»¶çš„æ ·æœ¬
    filtered = [
        item for item in compare_items
        if item["doc_id_diff"] >= 1 or abs(item["best_rank_delta"]) >= 2
    ]
    filtered = sorted(filtered, key=lambda x: x["best_rank_delta"], reverse=True)[:20]
    
    # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
    improved_count = sum(1 for item in filtered if item["best_rank_delta"] > 0)
    median_rank_delta = statistics.median([item["best_rank_delta"] for item in filtered]) if filtered else 0
    
    # ä¿å­˜ compare_batch_latest.json
    compare_batch = {
        "total": len(filtered),
        "improved_count": improved_count,
        "median_rank_delta": median_rank_delta,
        "items": filtered
    }
    
    compare_path = REPORTS_DIR / "compare_batch_latest.json"
    with open(compare_path, 'w') as f:
        json.dump(compare_batch, f, indent=2)
    print(f"\nâœ“ ä¿å­˜å¯¹æ¯”æ•°æ®: {compare_path}")
    
    # ä¿å­˜ judge_batch_latest.json (å…¼å®¹ /judge æ¸²æŸ“)
    judge_items = []
    for idx, item in enumerate(filtered):
        judge_items.append({
            "id": idx,
            "query": item["query"],
            "off": item["off"]["top3"],
            "on": item["on"]["top3"]
        })
    
    judge_batch = {
        "batch_id": "compare_latest",
        "total": len(judge_items),
        "items": judge_items
    }
    
    judge_path = REPORTS_DIR / "judge_batch_latest.json"
    with open(judge_path, 'w') as f:
        json.dump(judge_batch, f, indent=2)
    print(f"âœ“ ä¿å­˜æ ‡æ³¨æ•°æ®: {judge_path}")
    
    print("\n" + "=" * 60)
    print(f"âœ“ å®Œæˆï¼å…±ç­›é€‰ {len(filtered)} æ¡æ ·æœ¬")
    print(f"  æ”¹è¿›æ ·æœ¬: {improved_count}/{len(filtered)}")
    print(f"  ä¸­ä½æ’åæå‡: +{median_rank_delta}")
    print("=" * 60)
    
    return compare_batch


if __name__ == "__main__":
    mine_diff_cases()
