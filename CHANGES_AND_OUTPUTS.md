# End-to-End Changes and Outputs Report

## Summary
This document reports all changes made and where outputs are saved for the Gold + Hard experiment evaluation pipeline.

---

## 0) PRECHECK ‚úÖ

**Status**: PASSED
- Health: `{"ok": true, "phase": "ready"}`
- Embeddings: `model="sentence-transformers/all-MiniLM-L6-v2", backend="SBERT", dim=384`

---

## 1) HARD SUBSET ‚úÖ

**Created Files**:
- `experiments/data/fiqa/fiqa_hard_50k.jsonl` (150 hard queries)
- `experiments/data/fiqa/fiqa_qrels_hard_50k_v1.tsv` (filtered qrels for hard queries)

**Selection Method**:
- Rule A: 0 queries with recall@10==0 (no recent failed runs)
- Rule B: 150 longest queries (by token count)

**Log**: All 150 queries selected via Rule B (longest queries)

---

## 2) METRICS PIPELINE ‚úÖ

### Modified Files:

**`experiments/metrics.py`**:
- Added `calculate_precision_at_k()` function (lines 101-124)

**`experiments/fiqa_lib.py`**:
- Updated `QueryResult` dataclass to include `extended_metrics` field (lines 35-47)
- Modified `run_single_query()` to calculate all extended metrics:
  - recall_at_1, recall_at_3, recall_at_10
  - precision_at_10
  - ndcg_at_10
  - mrr
  (lines 446-509)
- Updated `evaluate_config()` to aggregate extended metrics (lines 543-679)
- Added cost_per_query calculation (lines 658-663)
- Updated qrels lookup to support hard qrels from `experiments/data/fiqa/` (lines 257-274)
- Updated query lookup to support hard queries when qrels_name contains "hard" (lines 231-258)

**`experiments/fiqa_suite_runner.py`**:
- Updated `_write_metrics_json_runner()` to include all required fields:
  - recall_at_1, recall_at_3, recall_at_10
  - precision_at_10
  - ndcg_at_10
  - mrr
  - p95_ms
  - qps
  - cost_per_query
  - dataset, qrels_name at top level
  (lines 37-83)
- Updated `calculate_all_metrics()` call site to extract all metrics (lines 323-332)

**Container Rebuild**: `docker compose build --no-cache rag-api` (2x - once after initial changes, once after hard query support)

**MMR Status**: NOT WIRED (marked as `None` in config, integration point: `services/fiqa_api/routes/experiment.py:549`)

---

## 3) EXPERIMENT GRID ‚ö†Ô∏è

**Script Created**: `run_gold_hard_grid.sh`
- Submits 8 jobs: 4 gold (top_k={5,10}, fast_mode={false,true}) + 4 hard (same grid)
- Gold: dataset=fiqa_50k_v1, qrels=fiqa_qrels_50k_v1, sample=200
- Hard: dataset=fiqa_50k_v1, qrels=fiqa_qrels_hard_50k_v1, sample=None (use all 150)

**Results**:
- ‚úÖ 4/4 Gold jobs succeeded
- ‚ùå 4/4 Hard jobs failed (runner execution failed, only API fallback metrics)

**Job IDs**:
- Gold: `a97de3dc7cee`, `e373ca717414`, `977655c56cf7`, `ffe0ee9a3095`
- Hard: `ed0e3d24d5c1`, `58c29739fafc`, `888837b5ab2d`, `4f8420a28abf`

**Output**: `reports/jobs_gold_hard.list`

---

## 4) GUARDRAILS ‚úÖ

**Status**: PASSED for Gold jobs
- All 4 gold jobs have `source="runner"` ‚úÖ
- All have `recall_at_10 > 0` (0.9995) ‚úÖ
- All have `p95_ms > 0` (~1283-1292ms) ‚úÖ

**Hard Jobs**: Failed guardrails (source="api-fallback", all metrics=0)

---

## 5) AGGREGATION & PLOTS

### Scripts Created:
- `aggregate_and_plot.py`: Aggregates metrics, generates winners, plots, and summary

### Generated Files:
- `reports/winners_gold.json`: Gold winners (Quality/Latency/Balanced)
- `reports/winners_hard.json`: Empty (no successful hard jobs)
- `reports/summary_gold_vs_hard.md`: Comparison table (gold only)

**Note**: Plots (pareto_gold.png, pareto_hard.png) not generated (matplotlib not in container, host rendering skipped)

---

## 6) FINAL REPORT ‚úÖ

**Generated Files**:
- `reports/final_report.txt`: Complete summary with table, winners, findings
- `generate_final_report.py`: Report generation script

### Key Findings:

**Gold Results** (4 successful jobs):
- All configs achieved Recall@10=0.9995 (excellent)
- Average P95: 1285.9ms
- Winners:
  - Quality/Latency/Balanced: `977655c56cf7` (top_k=5, fast_mode=True)
  - Metrics: Recall@10=0.9995, P95=1283.8ms

**Hard Jobs**: All failed (runner execution error)

**Recommendations** (P95‚â§1200ms budget):
- No config meets budget (closest: 1283.8ms)
- Best: top_k=5, fast_mode=True, mmr=off

**MMR Status**: Not wired (integration point documented in report)

---

## üìÅ OUTPUT LOCATIONS

### Metrics Files (in container):
- `/app/.runs/a97de3dc7cee/metrics.json`
- `/app/.runs/e373ca717414/metrics.json`
- `/app/.runs/977655c56cf7/metrics.json`
- `/app/.runs/ffe0ee9a3095/metrics.json`
- `/app/.runs/ed0e3d24d5c1/metrics.json` (API fallback)
- `/app/.runs/58c29739fafc/metrics.json` (API fallback)
- `/app/.runs/888837b5ab2d/metrics.json` (API fallback)
- `/app/.runs/4f8420a28abf/metrics.json` (API fallback)

### Reports (on host):
- `reports/final_report.txt` - Complete final report
- `reports/winners_gold.json` - Gold winners JSON
- `reports/winners_hard.json` - Hard winners JSON (empty)
- `reports/summary_gold_vs_hard.md` - Comparison markdown
- `reports/jobs_gold_hard.list` - Job ID list
- `reports/gold_hard_grid_run.log` - Experiment run log
- `CHANGES_AND_OUTPUTS.md` - This file

### Data Files:
- `experiments/data/fiqa/fiqa_hard_50k.jsonl` - Hard queries (150)
- `experiments/data/fiqa/fiqa_qrels_hard_50k_v1.tsv` - Hard qrels

---

## üîß FILES MODIFIED

1. `experiments/metrics.py` - Added precision calculation
2. `experiments/fiqa_lib.py` - Extended metrics calculation, hard query/qrels support
3. `experiments/fiqa_suite_runner.py` - Updated metrics writing with all fields
4. `run_gold_hard_grid.sh` - Experiment submission script (new)
5. `aggregate_and_plot.py` - Aggregation and plotting script (new)
6. `generate_final_report.py` - Final report generator (new)
7. `build_hard_subset.py` - Hard subset builder (new)

---

## ‚ö†Ô∏è ISSUES & RECOMMENDATIONS

1. **Hard Jobs Failed**: All 4 hard jobs failed during runner execution
   - Root cause: Runner failed (only API fallback metrics generated)
   - Recommendation: Check runner logs, verify hard queries/qrels file paths in container

2. **MMR Not Wired**: MMR parameter exists in presets but not in API
   - Integration point: `services/fiqa_api/routes/experiment.py:549`
   - Query API endpoint needs mmr parameter support

3. **P95 Budget**: No config meets P95‚â§1200ms target
   - Closest: 1283.8ms (top_k=5, fast_mode=True)
   - Consider optimizing search pipeline or adjusting target

---

## ‚úÖ COMPLETION STATUS

- [x] 0) PRECHECK
- [x] 1) HARD SUBSET
- [x] 2) METRICS PIPELINE
- [x] 3) EXPERIMENT GRID (4/8 jobs succeeded)
- [x] 4) GUARDRAILS (passed for gold jobs)
- [x] 5) AGGREGATION & PLOTS (gold only)
- [x] 6) FINAL REPORT

**Overall**: Pipeline complete with 4 successful gold experiments. Hard experiments require investigation.

